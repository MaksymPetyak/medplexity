{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Medplexity\n",
    "Medplexity is a framework to help explore capabilities of LLMs in the medical domain. We do this by providing interfaces and collections of common benchmarks, LLMs, and prompts. In this tutorial we will go over the main features of medplexity by running OpenAI's GPT-4 model against MedMCQA dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Let's start by installing the latest version of medplexity if you haven't already:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# !pip install medplexity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:02.761865Z",
     "start_time": "2023-10-05T11:10:02.707951Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmarks\n",
    "First let's select the benchmark that we want to evaluate against. In this example we are going with the MedMCQA dataset, which is a collection of multiple-choice questions to address real-world medical entrance exam questions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from medplexity.benchmarks.medmcqa.medmcqa_dataset_builder import MedMCQADatasetBuilder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:03.418178Z",
     "start_time": "2023-10-05T11:10:02.714759Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "medmcqa_dataset = MedMCQADatasetBuilder().build_dataset(split_type=\"validation\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.310666Z",
     "start_time": "2023-10-05T11:10:03.418647Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple-choice questions designed to address real-world medical entrance exam questions like AIIMS & NEET PG.\n",
      "    This dataset encompasses over 194k high-quality MCQs spanning 2.4k healthcare topics and 21 medical subjects. Questions are accompanied by an explanation of the correct answer.\n",
      "\n",
      "    Original paper: MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering\n",
      "\n",
      "    2022 · Ankit Pal, Logesh Kumar Umapathi, Malaikannan Sankarasubbu\n",
      "    <https://arxiv.org/abs/2203.14371>\n",
      "\n",
      "    Train/validation/test splits available.\n",
      "\n",
      "    Dataset version used: <https://huggingface.co/datasets/medmcqa>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(medmcqa_dataset.description)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.314859Z",
     "start_time": "2023-10-05T11:10:05.310977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{\n    \"input\": {\n        \"question\": \"Which of the following is not true about glomerular capillaries')\",\n        \"options\": [\n            \"The oncotic pressure of the fluid leaving the capillaries is less than that of fluid entering it\",\n            \"Glucose concentration in the capillaries is the same as that in glomerular filtrate\",\n            \"Constriction of afferent aeriole decreases the blood flow to the glomerulas\",\n            \"Hematocrit of the fluid leaving the capillaries is less than that of the fluid entering it\"\n        ]\n    },\n    \"expected_output\": 0,\n    \"metadata\": {\n        \"explanation\": \"Ans-a. The oncotic pressure of the fluid leaving the capillaries is less than that of fluid entering it Guyton I LpJ1 4-.;anong 23/e p653-6_)Glomerular oncotic pressure (due to plasma protein content) is higher than that of filtrate oncotic pressure in Bowman's capsule\\\"Since glucose is freely filtered and the fluid in the Bowman's capsule is isotonic with plasma, the concentration of glucose in the filtrate is the same as in the capillaries\",\n        \"subject_name\": \"Physiology\"\n    }\n}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data point\n",
    "medmcqa_dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.318722Z",
     "start_time": "2023-10-05T11:10:05.315708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LLMs & Chains\n",
    "Now let's create the LLMs that we want to use for the evaluation. Medplexity provides a interfaces to common APIs, such as OpenAI API. If you don't have an API key for OpenAI yet, you can get one on [Open AI website](https://openai.com/api)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from medplexity.llms.openai_caller import OpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.330457Z",
     "start_time": "2023-10-05T11:10:05.318850Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "openai_llm = OpenAI(\n",
    "    api_token=\"<YOUR TOKEN HERE>\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.333809Z",
     "start_time": "2023-10-05T11:10:05.331190Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's not enough to just have an LLM. We also need to find the right prompt to use, and then make sure that the output is in the correct format. For this reason, we use an abstraction of _Chain_. Chains are wrappers around complicated sequences of operations with LLMs at the core of it. If you are familiar with Langchain it's meant to be the same concept as the Chain there.\n",
    "\n",
    "For this specific benchmark we already have a prompt template that uses chain-of-thought prompting and a few examples. With this prompt we  also ask it to output a JSON of the format:\n",
    "```json\n",
    "{\n",
    "    \"answer\": \"...\",\n",
    "    \"explanation\": \"...\"\n",
    "}\n",
    "```\n",
    "to also get LLM's reasoning behind the answer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from medplexity.benchmarks.medmcqa.medmcqa_prompt_template import MedMCQAPromptTemplate\n",
    "\n",
    "prompt_template = MedMCQAPromptTemplate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.353094Z",
     "start_time": "2023-10-05T11:10:05.333950Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are multiple choice questions about medical knowledge. Solve them in a step-by-step fashion, starting by summarizing the available information. Output a JSON with the answer (give back only the letter) and an explanation for it.\n",
      "{examples}\n",
      "\n",
      "Question: {question}\n",
      "{options}\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.PROMPT)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.353408Z",
     "start_time": "2023-10-05T11:10:05.339347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are multiple choice questions about medical knowledge. Solve them in a step-by-step fashion, starting by summarizing the available information. Output a JSON with the answer (give back only the letter) and an explanation for it.\n",
      "Question: Maximum increase in prolactin level is caused by:\n",
      " (A) Risperidone (B) Clozapine (C) Olanzapine (D) Aripiprazole\n",
      "Output: {\"answer\":\"(A)\",\"explanation\":\"Let’s solve this step-by-step, referring to authoritative sources as needed. Clozapine generally does not raise prolactin levels. Atypicals such as olanzapine and aripiprazole cause small if no elevation. Risperidone is known to result in a sustained elevated prolactin level. Therefore risperidone is likely to cause the maximum increase in prolactin level.\"}\n",
      "\n",
      "Question: What is the age of routine screening mammography?\n",
      " (A) 20 years (B) 30 years (C) 40 years (D) 50 years\n",
      "Output: {\"answer\":\"(C)\",\"explanation\":\"Let’s solve this step-by-step, referring to authoritative sources as needed. The age of routine screening depends on the country you are interested in and varies widely. For the US, it is 40 years of age according to the American Cancer Society. In Europe, it is typically closer to 50 years. For a patient based in the US, the best answer is 40 years.\"}\n",
      "\n",
      "Question: A 65-year-old male complains of severe back pain and inability to move his left lower limb. Radiographic studies demonstrate the compression of nerve elements at the intervertebral foramen between vertebrae L5 and S1. Which structure is most likely responsible for this space-occupying lesion?\n",
      " (A) Anulus fibrosus (B) Nucleus pulposus (C) Posterior longitudinal ligament (D) Anterior longitudinal ligament\n",
      "Output: {\"answer\":\"(B)\",\"explanation\":\"Let’s solve this step-by-step, referring to authoritative sources as needed. This man describes a herniated invertebral disk through a tear in the surrounding annulus fibrosus. The soft, gelatinous \\\"nucleus pulposus\\\" is forced out through a weakened part of the disk, resulting in back pain and nerve root irritation. In this case, the impingement is resulting in paralysis, and should be considered a medical emergency. Overall, the structure that is causing the compression and symptoms is the nucleus pulposus.\"}\n",
      "\n",
      "Question: Neuroendocrine cells in the lungs are:\n",
      " (A) Dendritic cells (B) Type I pneumocytes (C) Type II pneumocytes (D) APUD cells\n",
      "Output: {\"answer\":\"(D)\",\"explanation\":\"Let’s solve this step-by-step, referring to authoritative sources as needed. Neuroendocrine cells, which are also known as Kultschitsky-type cells, Feyrter cells and APUD cells, are found in the basal layer of the surface epithelium and in the bronchial glands.\"}\n",
      "\n",
      "Question: Presence of it indicates remote contamination of water\n",
      " (A) Streptococci (B) Staphalococci (C) Clastridium pertringes (D) Nibrio\n",
      "Output: {\"answer\":\"(C)\",\"explanation\":\"Let’s solve this step-by-step, referring to authoritative sources as needed. Because Clostridium perfringens spores are both specific to sewage contamination and environmentally stable, they are considered as possible conservative indicators of human fecal contamination and possible surrogates for environmentally stable pathogens.\"}\n",
      "\n",
      "\n",
      "Question: A 29 yrs old woman with a pregnancy of 17 week has a 10 years old boy with down syndrome. She does not want another down syndrome kid; best advice to her is\n",
      "(A) No test is required now as her age is below 35 years (B) Ultra sound at this point of time will definitely tell her that next baby will be down syndromic or not (C) Amniotic fluid samples plus chromosomal analysis will definitely tell her that next baby will be down syndromic or not (D) blood screening at this point of time will clear the exact picture\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "example_datapoint = medmcqa_dataset[2]\n",
    "\n",
    "# Here is how a final prompt would look like\n",
    "print(prompt_template.format(\n",
    "    question=example_datapoint.input.question,\n",
    "    options=example_datapoint.input.options\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.353557Z",
     "start_time": "2023-10-05T11:10:05.342071Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To prepare LLM for the evaluation we will need to transform the dataset inputs into the right prompt, then transform the output from LLM into the expected format (JSON of answer and explanation), and use that format in the comparison with the expected answer in the dataset (which is a single number). Right now, with medplexity the way to do it is by defining small adapter functions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from medplexity.benchmarks.multiple_choice_utils import AnswerWithExplanation\n",
    "from medplexity.benchmarks.medmcqa.medmcqa_dataset_builder import MedMCQAInput\n",
    "\n",
    "def input_adapter(medmcqa_input: MedMCQAInput) -> str:\n",
    "    \"\"\"Transforms input into a single string that will be passed down to LLM\"\"\"\n",
    "    prompt_template = MedMCQAPromptTemplate()\n",
    "\n",
    "    return prompt_template.format(\n",
    "        question=medmcqa_input.question,\n",
    "        options=medmcqa_input.options\n",
    "    )\n",
    "\n",
    "def output_adapter(output_json: str) -> AnswerWithExplanation:\n",
    "    \"\"\"Parses the output string to the expected JSON format, for which we use a Pydantic model\"\"\"\n",
    "    parsed_output = AnswerWithExplanation.model_validate_json(output_json)\n",
    "\n",
    "    return parsed_output\n",
    "\n",
    "def comparator(expected_output: int, predicted_output: AnswerWithExplanation):\n",
    "    \"\"\"Compare the answer with the expected output in the dataset.\n",
    "\n",
    "    Since in the dataset it's a number that is used to indicate the right answer we convert it to the corresponding letter.\n",
    "    \"\"\"\n",
    "\n",
    "    letter_to_idx = { \"(A)\" : 0, \"(B)\": 1, \"(C)\": 2, \"(D)\": 3 }\n",
    "    predicted_idx =  letter_to_idx[predicted_output.answer]\n",
    "\n",
    "    return expected_output == predicted_idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.353661Z",
     "start_time": "2023-10-05T11:10:05.346624Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can define the final chain and go on to evaluation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from medplexity.chains.evaluation_adapter_chain import EvaluationAdapterChain\n",
    "\n",
    "chain = EvaluationAdapterChain(\n",
    "    llm=openai_llm,\n",
    "    input_adapter=input_adapter,\n",
    "    output_adapter=output_adapter,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.361504Z",
     "start_time": "2023-10-05T11:10:05.351016Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "Evaluators accept your chain and then can run it on a given dataset. They will generate a report that you can later examine on level of individual predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from medplexity.evaluators.sequential_evaluator import SequentialEvaluator\n",
    "\n",
    "evaluator = SequentialEvaluator(\n",
    "    chain=chain,\n",
    "    comparator=comparator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:05.367468Z",
     "start_time": "2023-10-05T11:10:05.356006Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can evaluate our model on a subset of MedMCQA dataset. Beware, that calling the cell below will actaully use your OpenAI credits to make predictions (which is why we call just on a small subset of the dataset)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# BEWARE!: calling this will actually consume your OpenAI credits, that's why we run on a very small subset\n",
    "evaluation = evaluator.evaluate(medmcqa_dataset[5:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:21.108789Z",
     "start_time": "2023-10-05T11:10:05.363768Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.accuracy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:21.109556Z",
     "start_time": "2023-10-05T11:10:21.104173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "correct, incorrect = evaluation.partition_by_correctness()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:21.116132Z",
     "start_time": "2023-10-05T11:10:21.110839Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can also examine incorrect results:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "{\n    \"input\": {\n        \"question\": \"Which of the following are not a branch of external carotid Aery in Kiesselbach's plexus.\",\n        \"options\": [\n            \"Sphenopalatine aery\",\n            \"Anterior ethmoidal aery\",\n            \"Greater palatine aery\",\n            \"Septal branch of superior labial aery\"\n        ]\n    },\n    \"input_metadata\": {\n        \"explanation\": \"*Kiesselbach's plexus: Antero superior pa is supplied by ANTERIOR & POSTERIOR ETHMOIDAL AERIES which are branches of ophthalmic aery, branch of INTERNAL CAROTID AERY. Antero inferior pa is supplied by SUPERIOR LABIAL AERY - branch of facial aery, which is branch of EXTERNAL CAROTID AERY. Postero superior pa is supplied by SPHENO-PALATINE AERY - branch of MAXILLARY aery, which is branch of ECA. POSTERO INFERIOR pa is supplied by branches of GREATER PALATINE AERY - branch of ECA Antero inferior pa/vestibule of septum contain anastomosis b/w septal ramus of superior labial branch of facial aery & branches of sphenopalatine, greater palatine & anterior ethmoidal aeries. These form a large capillary network called KIESSELBACH'S PLEXUS If dryness persists, bleeding will occur Therefore, in given options, Anterior ethmoidal aery is a branch of ICA not ECA\",\n        \"subject_name\": \"Anatomy\"\n    },\n    \"expected_output\": 1,\n    \"output\": {\n        \"answer\": \"(C)\",\n        \"explanation\": \"Let’s solve this step-by-step, referring to authoritative sources as needed. Kiesselbach's plexus is an area in the anterior part of the nasal septum where several arteries converge. The branches of the external carotid artery that contribute to Kiesselbach's plexus include the sphenopalatine artery, anterior ethmoidal artery, and septal branch of the superior labial artery. The greater palatine artery is not a branch of the external carotid artery and therefore does not contribute to Kiesselbach's plexus.\"\n    },\n    \"output_metadata\": null,\n    \"correct\": false\n}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output was (B) and not (C)\n",
    "incorrect[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:21.123886Z",
     "start_time": "2023-10-05T11:10:21.113963Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, you can also save this in a file to later have a look at the results or visualise them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "evaluation.save(\"medmcqa_validation_evaluation.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T11:10:21.124122Z",
     "start_time": "2023-10-05T11:10:21.117834Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can learn more about the available benchmarks in our [docs](https://medplexity.readthedocs.io/en/latest/)."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
